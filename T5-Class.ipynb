{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d391d20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import copy\n",
    "from tqdm.notebook import tqdm\n",
    "import gc\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    f1_score, \n",
    "    classification_report\n",
    ")\n",
    "\n",
    "from transformers import (\n",
    "    T5Tokenizer, \n",
    "    T5Model,\n",
    "    T5ForConditionalGeneration,\n",
    "    get_linear_schedule_with_warmup\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1fc41f38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quote</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i liked being a person. i wanted to keep at it.</td>\n",
       "      <td>life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>my wishes before i die, to fulfill my mission ...</td>\n",
       "      <td>inspirational inspirational-quotes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i was just thinking that he might be willing. ...</td>\n",
       "      <td>humor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>joyful peace pervades my being for all time.</td>\n",
       "      <td>inspirational-quotes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>don't let what other people think, stop you fr...</td>\n",
       "      <td>philosophy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129029</th>\n",
       "      <td>just smile, breath, and give thanks (and there...</td>\n",
       "      <td>life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129030</th>\n",
       "      <td>the dreamers, those who misread the actual sta...</td>\n",
       "      <td>truth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129031</th>\n",
       "      <td>i will gladly spend the rest of my days learni...</td>\n",
       "      <td>happiness faith love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129032</th>\n",
       "      <td>for it is beautiful only to do the thing we ar...</td>\n",
       "      <td>life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129033</th>\n",
       "      <td>religion serves all of us; men, women, gays, s...</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>129034 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    quote  \\\n",
       "0         i liked being a person. i wanted to keep at it.   \n",
       "1       my wishes before i die, to fulfill my mission ...   \n",
       "2       i was just thinking that he might be willing. ...   \n",
       "3            joyful peace pervades my being for all time.   \n",
       "4       don't let what other people think, stop you fr...   \n",
       "...                                                   ...   \n",
       "129029  just smile, breath, and give thanks (and there...   \n",
       "129030  the dreamers, those who misread the actual sta...   \n",
       "129031  i will gladly spend the rest of my days learni...   \n",
       "129032  for it is beautiful only to do the thing we ar...   \n",
       "129033  religion serves all of us; men, women, gays, s...   \n",
       "\n",
       "                                      tags  \n",
       "0                                     life  \n",
       "1       inspirational inspirational-quotes  \n",
       "2                                    humor  \n",
       "3                     inspirational-quotes  \n",
       "4                               philosophy  \n",
       "...                                    ...  \n",
       "129029                                life  \n",
       "129030                               truth  \n",
       "129031                happiness faith love  \n",
       "129032                                life  \n",
       "129033                           happiness  \n",
       "\n",
       "[129034 rows x 2 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "train_df[\"tags\"] = train_df[\"tags\"].apply(lambda x: \" \".join(x.split(\"_\")))\n",
    "\n",
    "labels = ['love','life','inspirational','philosophy','humor','god','truth','wisdom','happiness','people','hope','time','faith','quotes','inspirational-quotes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "82b2b75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "seed = 9\n",
    "val_split = 0.1\n",
    "batch_size = 20\n",
    "epochs = 10\n",
    "np.random.seed(seed)\n",
    "\n",
    "dataset_size = len(train_df)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(val_split * dataset_size))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "train_indices, val_indices = indices[split:], indices[:split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5836339",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_one_hot_encoding(labels, text):\n",
    "    one_hot_encoding = np.zeros(len(labels), dtype=int)\n",
    "    \n",
    "    for i, label in enumerate(labels):\n",
    "        if label in text:\n",
    "            one_hot_encoding[i] = 1\n",
    "    \n",
    "    return one_hot_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70540537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# created dataset class for classification\n",
    "\n",
    "class ClassificationDataset(Dataset):\n",
    "    def __init__(self, dataframe, indices, tokenizer):\n",
    "        super(ClassificationDataset, self).__init__()\n",
    "\n",
    "        df = dataframe.iloc[indices]\n",
    "        self.texts = df['quote'].tolist()\n",
    "        self.targets = df['tags'].tolist()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.src_max_length = 512 # based on longest quote\n",
    "        self.tgt_max_length = 20\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        target = str(self.targets[idx])\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            max_length=self.src_max_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        target_enc = self.tokenizer.encode_plus(\n",
    "            target,\n",
    "            max_length=self.tgt_max_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        input_ids = encoding[\"input_ids\"].squeeze()\n",
    "        attention_mask = encoding[\"attention_mask\"].squeeze()\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"target_ids\": target_enc[\"input_ids\"].squeeze(),\n",
    "            \"target_attn_mask\": target_enc[\"attention_mask\"].squeeze()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "14a07456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "680846b4a8bf435593c73a6f6c461e55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ff3872c79c24256a90b672ccb9032b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "315544fbd96143d8ad8d17bff8f7dbf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd02c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fc1139",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = ClassificationDataset(train_df, train_indices, tokenizer)\n",
    "val_data = ClassificationDataset(train_df, val_indices, tokenizer)\n",
    "train_dataloader = DataLoader(training_data, batch_size= batch_size)\n",
    "validation_dataloader = DataLoader(val_data, batch_size= batch_size)\n",
    "\n",
    "#batch = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aec6af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dl, val_dl ,criterion, optimizer, scheduler, epochs):\n",
    "    # we validate config.N_VALIDATE_DUR_TRAIN times during the training loop\n",
    "    nv = 10\n",
    "    temp = len(train_dataloader) // nv\n",
    "    temp = temp - (temp % 100)\n",
    "    validate_at_steps = [temp * x for x in range(1, nv + 1)]\n",
    "    \n",
    "    train_loss = 0\n",
    "    for step, batch in enumerate(tqdm(train_dataloader, \n",
    "                                      desc='Epoch ' + str(epochs))):\n",
    "        # set model.eval() every time during training\n",
    "        model.train()\n",
    "        \n",
    "        # unpack the batch contents and push them to the device (cuda or cpu).\n",
    "        b_src_input_ids = batch['input_ids']\n",
    "        b_src_attention_mask = batch['attention_mask']\n",
    "    \n",
    "        lm_labels = batch['target_ids']\n",
    "        lm_labels[lm_labels[:, :] == tokenizer.pad_token_id] = -100\n",
    "\n",
    "        b_tgt_attention_mask = batch['target_attn_mask']\n",
    "\n",
    "        # clear accumulated gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward pass\n",
    "        outputs = model(input_ids=b_src_input_ids, \n",
    "                        attention_mask=b_src_attention_mask,\n",
    "                        labels=lm_labels,\n",
    "                        decoder_attention_mask=b_tgt_attention_mask)\n",
    "        loss = outputs[0]\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # update weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        # update scheduler\n",
    "        scheduler.step()\n",
    "\n",
    "        if step in validate_at_steps:\n",
    "            print(f'-- Step: {step}')\n",
    "            _ = val(model, val_dataloader, criterion)\n",
    "    \n",
    "    avg_train_loss = train_loss / len(train_dataloader)\n",
    "    print('Training loss:', avg_train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f6bca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(model, val_dataloader, criterion):\n",
    "    \n",
    "    val_loss = 0\n",
    "    true, pred = [], []\n",
    "    \n",
    "    # set model.eval() every time during evaluation\n",
    "    model.eval()\n",
    "    \n",
    "    for step, batch in enumerate(val_dataloader):\n",
    "        # unpack the batch contents and push them to the device (cuda or cpu).\n",
    "        b_src_input_ids = batch['input_ids']\n",
    "        b_src_attention_mask = batch['attention_mask']\n",
    "    \n",
    "        b_tgt_input_ids = batch['target_ids']\n",
    "        lm_labels = b_tgt_input_ids\n",
    "        lm_labels[lm_labels[:, :] == tokenizer.pad_token_id] = -100\n",
    "\n",
    "        b_tgt_attention_mask = batch['target_attn_mask']\n",
    "\n",
    "        # using torch.no_grad() during validation/inference is faster -\n",
    "        # - since it does not update gradients.\n",
    "        with torch.no_grad():\n",
    "            # forward pass\n",
    "            outputs = model(\n",
    "                input_ids=b_src_input_ids, \n",
    "                attention_mask=b_src_attention_mask,\n",
    "                labels=lm_labels,\n",
    "                decoder_attention_mask=b_tgt_attention_mask)\n",
    "            loss = outputs[0]\n",
    "\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # get true \n",
    "            for true_id in b_tgt_input_ids:\n",
    "                true_decoded = tokenizer.decode(true_id)\n",
    "                true.append(true_decoded)\n",
    "\n",
    "            # get pred (decoder generated textual label ids)\n",
    "            pred_ids = model.t5_model.generate(\n",
    "                input_ids=b_src_input_ids, \n",
    "                attention_mask=b_src_attention_mask\n",
    "            )\n",
    "            pred_ids = pred_ids.cpu().numpy()\n",
    "            for pred_id in pred_ids:\n",
    "                pred_decoded = tokenizer.decode(pred_id)\n",
    "                pred.append(pred_decoded)\n",
    "\n",
    "    true_ohe = generate_one_hot_encoding(true)\n",
    "    pred_ohe = generate_one_hot_encoding(pred)\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_dataloader)\n",
    "    print('Val loss:', avg_val_loss)\n",
    "    print('Val accuracy:', accuracy_score(true_ohe, pred_ohe))\n",
    "\n",
    "    val_micro_f1_score = f1_score(true_ohe, pred_ohe, average='micro')\n",
    "    print('Val micro f1 score:', val_micro_f1_score)\n",
    "    return val_micro_f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748ceb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    # setting a seed ensures reproducible results.\n",
    "    # seed may affect the performance too.\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_parameters = [\n",
    "        {\n",
    "            \"params\": [\n",
    "                p for n, p in param_optimizer if not any(nd in n for nd in no_decay)\n",
    "            ],\n",
    "            \"weight_decay\": 0.001,\n",
    "        },\n",
    "        {\n",
    "            \"params\": [\n",
    "                p for n, p in param_optimizer if any(nd in n for nd in no_decay)\n",
    "            ],\n",
    "            \"weight_decay\": 0.0,\n",
    "        },\n",
    "    ]\n",
    "    optimizer = optim.AdamW(optimizer_parameters, lr=2e-5)\n",
    "\n",
    "    num_training_steps = len(train_dataloader) * epochs\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=0,\n",
    "        num_training_steps=num_training_steps\n",
    "    )\n",
    "\n",
    "    max_val_micro_f1_score = float('-inf')\n",
    "    for epoch in range(epochs):\n",
    "        train(model, train_dataloader, validation_dataloader, criterion, optimizer, scheduler, epoch)\n",
    "        val_micro_f1_score = val(model, validation_dataloader, criterion)\n",
    "\n",
    "        if True:\n",
    "            if val_micro_f1_score > max_val_micro_f1_score:\n",
    "                best_model = copy.deepcopy(model)\n",
    "                best_val_micro_f1_score = val_micro_f1_score\n",
    "\n",
    "                model_name = 't5_best_model'\n",
    "                #torch.save(best_model.state_dict(), model_name + '.pt')\n",
    "\n",
    "                print(f'--- Best Model. Val loss: {max_val_micro_f1_score} -> {val_micro_f1_score}')\n",
    "                max_val_micro_f1_score = val_micro_f1_score\n",
    "\n",
    "    return best_model, best_val_micro_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f401913",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model, best_val_micro_f1_score = run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80ac0f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
